{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Mini-Project: Comparing Trump's and Biden's Inaugural Speeches\n",
    "\n",
    "We will use a mini CSS project as an extended example to put into practice the concepts we are learning. The project aims to analyze and compare the inaugural speeches of the current and last US presidents. We will guide you through each successive step.\n",
    "\n",
    "The speech transcripts were obtained from https://millercenter.org/the-presidency/presidential-speeches and copied in the text files `biden_inauguration_millercenter.txt` and `trump_inauguration_millercenter.txt` in the `data` folder.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Import data\n",
    "\n",
    "First, we will get the data into a Python-native format. Create a function that reads one of the text files into a single string and returns the string. We have provided some skeleton code for you to use.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "trump = \"/Users/loiswong/Downloads/css/data/trump_inauguration_millercenter.txt\"\n",
    "biden = \"/Users/loiswong/Downloads/css/data/biden_inauguration_millercenter.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_text(fname):\n",
    "    \"\"\"Read given text file and return a string with the contents.\"\"\"\n",
    "    \n",
    "    # Open the file and get the text into a string variable called txt\n",
    "    with open(fname) as f:\n",
    "        txt = f.read()\n",
    "        \n",
    "    # Remove any trailing white space and paragraphs\n",
    "    # Format consistently by replacing ’ with '\n",
    "    return txt.strip().replace(\"’\", \"'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chief Justice Roberts, President Carter, President Clinton, President Bush, President Obama, fellow Americans, and people of the world: thank you.\n",
      "\n",
      "We, the citizens of America, are now joined in a great national effort to rebuild our country and to restore its promise for all of our people.\n",
      "\n",
      "Together, we will determine the course of America and the world for years to come.\n",
      "\n",
      "We will face challenges. We will confront hardships. But we will get the job done.\n",
      "\n",
      "Every four years, we gather on these st\n"
     ]
    }
   ],
   "source": [
    "# Call the function on Trump's speech and print the first 500 words\n",
    "trump = get_text(trump)\n",
    "print(trump[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Clean and tokenize text\n",
    "\n",
    "In the next step, we will process the data so that a machine can analyze it. Create another function called `get_tokens()` that takes a string with something that looks like a speech, cleans up the text, and extract a list of all the words used in the speech in the order they appear. We have provided some clues below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_tokens(txt):\n",
    "    \"\"\"Take given string and return a list with all words in lowercase\n",
    "    in the order they appear in the text. Common contractions are expanded\n",
    "    and hyphenated words are combined in one word.\n",
    "    \"\"\"\n",
    "    modified = txt.lower().replace(\"'\", \"\").replace(\"I've\", \"I have\").replace(\"can't\", \"cannot\")\n",
    "    modified.replace(\",\", \"\").replace(\".\", \"\").replace(\":\", \"\").replace(\"–\", \"\")\n",
    "    return list(modified.split(\" \"))\n",
    "                \n",
    "    # Get rid of possessives so that nation's becomes nation \n",
    "    # Expand contractions such that I've becomes I have, can't becomes cannot, etc.\n",
    "    # Remove all punctuation \n",
    "    # Convert to lower-case      \n",
    "    # Break into words\n",
    "    # Return the list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chief', 'justice', 'roberts,', 'president', 'carter,', 'president', 'clinton,', 'president', 'bush,', 'president', 'obama,', 'fellow', 'americans,', 'and', 'people', 'of', 'the', 'world:', 'thank', 'you.\\n\\nwe,', 'the', 'citizens', 'of', 'america,', 'are', 'now', 'joined', 'in', 'a', 'great', 'national', 'effort', 'to', 'rebuild', 'our', 'country', 'and', 'to', 'restore', 'its', 'promise', 'for', 'all', 'of', 'our', 'people.\\n\\ntogether,', 'we', 'will', 'determine', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Call the function on Trump's speech and print the first 50 tokens\n",
    "trump_tokens = get_tokens(trump)\n",
    "print(trump_tokens[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Count words\n",
    "\n",
    "Now, tokenize Biden's speech in the same way. How many words does each speech contains? Who has the longer speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chief', 'justice', 'roberts,', 'vice', 'president', 'harris,', 'speaker', 'pelosi,', 'leader', 'schumer,', 'leader', 'mcconnell,', 'vice', 'president', 'pence,', 'distinguished', 'guests,', 'and', 'my', 'fellow', 'americans.\\n\\nthis', 'is', 'americas', 'day.\\n\\nthis', 'is', 'democracys', 'day.\\n\\na', 'day', 'of', 'history', 'and', 'hope.\\n\\nof', 'renewal', 'and', 'resolve.\\n\\nthrough', 'a', 'crucible', 'for', 'the', 'ages', 'america', 'has', 'been', 'tested', 'anew', 'and', 'america', 'has', 'risen', 'to']\n"
     ]
    }
   ],
   "source": [
    "biden_tokens = get_tokens(biden)\n",
    "biden = get_text(biden)\n",
    "print(biden_tokens[:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Evaluate vocabulary\n",
    "\n",
    "Next, look at the unique words used by each speaker. Who uses more unique words? Whose speech is more repetitive?\n",
    "\n",
    "Biden has more unique words in his speech than Trump."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trump has 628 unique words in his speech\n"
     ]
    }
   ],
   "source": [
    "#unique words from Trump's speech \n",
    "trump_unique_words = set(trump_tokens)\n",
    "\n",
    "#number of unique words\n",
    "print(\"Trump has\", len(trump_unique_words), \"unique words in his speech\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biden has 905 unique words in his speech\n"
     ]
    }
   ],
   "source": [
    "#unique words from Biden's speech\n",
    "biden_unique_words = set(biden_tokens)\n",
    "\n",
    "#number of unique words\n",
    "print(\"Biden has\", len(biden_unique_words), \"unique words in his speech\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Discover the main themes\n",
    "\n",
    "Finally, we will identify the most repeated words, which will give us an idea of the main recurring themes in the speeches.\n",
    "\n",
    "To begin with, write a function that identifies the most commonly used meaningful words. We will count the number of times each unique word is mentioned in the speech but exclude non-meaningful words such as articles and prepositions, because these are trivially common. \n",
    "\n",
    "Use the helping code below and write your code around it to complete the function and call it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# We declare a global variable to list stop words. \n",
    "# Stop words are common words that are not meaningful in this context.\n",
    "STOP_WORDS = ['a', 'about', 'across', 'after', 'an', 'and', 'any', 'are', 'as', 'at', \n",
    "              'be', 'because', 'but', 'by', 'did', 'do', 'does', 'for', 'from',\n",
    "              'get', 'has', 'have', 'if', 'in', 'is', 'it', 'its',\n",
    "              'many', 'more', 'much', 'no', 'not', 'of', 'on', 'or', 'out',\n",
    "              'so', 'some', 'than', 'the', 'this', 'that', 'those', 'through', 'to',\n",
    "              'very', 'what', 'where', 'whether', 'which', 'while', 'who', 'with']\n",
    "\n",
    "\n",
    "def get_word_counts(tokens, stopwords = STOP_WORDS):\n",
    "    \"\"\"Take a list of tokens and a list of stopwords and \n",
    "    return a list with the unique meaningful words (words that are not stopwords)\n",
    "    sorted by how often they appear. The list contains (word, count) tuples \n",
    "    and is sorted in descending order by count.\n",
    "    \"\"\"\n",
    "    # Create an empty dictionary where we will have word: count\n",
    "    count_dic = {}\n",
    "    \n",
    "    # For each token, if it is not in stopwords, either add it as a key with \n",
    "    # count 1 if it is new, or increase its count by 1 if it already exists\n",
    "    for word in tokens:\n",
    "        if word not in STOP_WORDS:\n",
    "            if word not in count_dic.keys():\n",
    "                count_dic[word] = 1\n",
    "            else:\n",
    "                count_dic[word] += 1       \n",
    "    \n",
    "    # Get the dictionary items as tuples and sort them by the counts in descending order\n",
    "    sorted_word_counts = sorted(count_dic.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Return\n",
    "    return sorted_word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now, identify the 10 most commonly used meaningful words for Trump and Biden to reveal the theme and tone of their speech. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('our', 48), ('will', 40), ('we', 26), ('all', 12), ('–', 11), ('american', 11), ('their', 10), ('your', 10), ('america', 9), ('people', 6)]\n"
     ]
    }
   ],
   "source": [
    "#Trump's most commonly used meaningful words\n",
    "trump_counts = get_word_counts(trump_tokens)\n",
    "print(trump_counts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('we', 59), ('our', 42), ('will', 29), ('my', 16), ('can', 16), ('us', 16), ('one', 14), ('all', 14), ('i', 13), ('america', 10)]\n"
     ]
    }
   ],
   "source": [
    "##Biden's most commonly used meaningful words\n",
    "biden_counts = get_word_counts(biden_tokens)\n",
    "print(biden_counts[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In the end, can you get the words that are unique to either Trump or Biden? These are words that Trump mentions at least twice but Biden doesn't, and vice versa. We impose the rule of the word being repeated to get more robust results. Do you notice any trends?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# only keep pairs where the value > 2 \n",
    "def count_filter(dict):\n",
    "    key, value = dict\n",
    "    if value > 1:\n",
    "        return True  # keep pair in the filtered dictionary\n",
    "    else:\n",
    "        return False  # filter pair out of the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['back',\n",
       " '',\n",
       " 'bring',\n",
       " 'again.\\n\\nwe',\n",
       " 'too',\n",
       " 'factories',\n",
       " 'protected',\n",
       " 'everyone',\n",
       " 'millions',\n",
       " 'foreign',\n",
       " 'countries',\n",
       " 'heart',\n",
       " 'citizens',\n",
       " 'now',\n",
       " 'obama',\n",
       " 'transferring',\n",
       " 'party',\n",
       " 'small',\n",
       " 'government',\n",
       " 'share',\n",
       " 'capital,',\n",
       " 'belongs',\n",
       " 'forgotten',\n",
       " 'men',\n",
       " 'movement',\n",
       " 'stops',\n",
       " 'glorious',\n",
       " 'allegiance',\n",
       " 'borders',\n",
       " 'made',\n",
       " 'workers',\n",
       " 'jobs.',\n",
       " 'breath',\n",
       " 'winning',\n",
       " 'life',\n",
       " 'old',\n",
       " 'loyalty',\n",
       " 'talk',\n",
       " 'dreams,']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words Trump used 2+ times \n",
    "trump_top_words = dict(filter(count_filter, trump_counts)) \n",
    "\n",
    "# words Trump used 2+ times and Biden used 0 times \n",
    "trump_top_words_unique = [word for word in trump_top_words.keys() if word not in biden_unique_words]\n",
    "trump_top_words_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me',\n",
       " 'story',\n",
       " 'know',\n",
       " 'days',\n",
       " 'history',\n",
       " 'democracy',\n",
       " 'come',\n",
       " 'war,',\n",
       " 'soul',\n",
       " 'need',\n",
       " 'vice',\n",
       " 'them',\n",
       " 'sacred',\n",
       " 'centuries',\n",
       " 'were',\n",
       " 'lost',\n",
       " 'cry',\n",
       " 'whole',\n",
       " 'join',\n",
       " 'common',\n",
       " 'unity',\n",
       " 'once',\n",
       " 'meet',\n",
       " 'better',\n",
       " 'believe',\n",
       " 'stand,',\n",
       " 'gave',\n",
       " 'say',\n",
       " 'truth',\n",
       " 'do,',\n",
       " 'may',\n",
       " 'leader',\n",
       " 'ages',\n",
       " 'tested',\n",
       " 'cause',\n",
       " 'again',\n",
       " 'friends,',\n",
       " 'ago',\n",
       " 'violence',\n",
       " 'nation,',\n",
       " 'ahead',\n",
       " 'set',\n",
       " 'constitution',\n",
       " 'strength',\n",
       " 'spoke',\n",
       " 'last',\n",
       " 'today,',\n",
       " 'his',\n",
       " 'taken',\n",
       " '—',\n",
       " 'still',\n",
       " 'difficult',\n",
       " 'year',\n",
       " 'war',\n",
       " 'thousands',\n",
       " 'racial',\n",
       " 'comes',\n",
       " 'cant',\n",
       " 'rise',\n",
       " 'overcome',\n",
       " 'future',\n",
       " 'requires',\n",
       " 'things',\n",
       " 'january',\n",
       " 'act',\n",
       " 'nation.\\n\\ni',\n",
       " 'ask',\n",
       " 'virus.\\n\\nwe',\n",
       " 'sound',\n",
       " 'civil',\n",
       " 'enough',\n",
       " 'forward.\\n\\nand,',\n",
       " 'show',\n",
       " 'way,',\n",
       " 'stop',\n",
       " 'unity,',\n",
       " 'peace,',\n",
       " 'progress,',\n",
       " 'raging',\n",
       " 'disagreement',\n",
       " 'measure',\n",
       " 'support',\n",
       " 'this:',\n",
       " 'saint',\n",
       " 'objects',\n",
       " 'leaders',\n",
       " 'honor',\n",
       " 'americans',\n",
       " 'turn',\n",
       " 'dont',\n",
       " 'versus',\n",
       " 'called',\n",
       " 'how',\n",
       " 'would',\n",
       " 'silent',\n",
       " 'prayer',\n",
       " 'resolve',\n",
       " 'write',\n",
       " 'shall',\n",
       " 'give',\n",
       " 'hope,',\n",
       " 'us.\\n\\nthe']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words Biden used 2+ times \n",
    "biden_top_words = dict(filter(count_filter, biden_counts)) \n",
    "\n",
    "# words Biden used 2+ times and Trump used 0 times \n",
    "biden_top_words_unique = [word for word in biden_top_words.keys() if word not in trump_unique_words]\n",
    "biden_top_words_unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
